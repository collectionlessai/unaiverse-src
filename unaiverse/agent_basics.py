import os
import torch
import pickle
from PIL.Image import Image
from unaiverse.clock import Clock
from unaiverse.hsm import HybridStateMachine
from unaiverse.networking.p2p.messages import Msg
from unaiverse.dataprops import DataProps, Data4Proc
from unaiverse.networking.node.profile import NodeProfile
from unaiverse.streams import BufferedDataStream, DataStream
from unaiverse.networking.node.connpool import ConnectionPools
from unaiverse.library.modules.utils import AgentProcessorChecker, ModuleWrapper


class AgentBasics:
    """This class contains those methods and properties that are about building the agent, known agents,
    known streams, etc., and no actions at all (see the class "Agent" for actions)."""

    DEBUG = True  # turns on/off extra logging

    # role bits (a.k.a. role int): default roles, shared by every possible agent
    ROLE_PUBLIC = 0 << 0
    ROLE_WORLD_MASTER = (1 << 0) | (1 << 1)
    ROLE_WORLD_AGENT = (1 << 0) | (0 << 1)

    # from role bits (int) to string
    ROLE_BITS_TO_STR = {
        ROLE_PUBLIC: "public_agent",
        ROLE_WORLD_MASTER: "world_master",
        ROLE_WORLD_AGENT: "world_agent",
    }

    # from role string to bits (int)
    ROLE_STR_TO_BITS = {
        "public_agent": ROLE_PUBLIC,
        "world_master": ROLE_WORLD_MASTER,
        "world_agent": ROLE_WORLD_AGENT,
    }

    # types of badges
    BADGE_TYPES = {'completed', 'attended', 'intermediate', 'pro'}

    def __init__(self,
                 proc: ModuleWrapper | torch.nn.Module | None,
                 proc_inputs: list[Data4Proc] | None = None,
                 proc_outputs: list[Data4Proc] | None = None,
                 proc_opts: dict | None = None,
                 behav: HybridStateMachine | None = None,
                 merge_flat_stream_labels: bool = False,
                 buffer_generated: bool = False,
                 buffer_generated_by_others: str = "none"):
        """Create a new agent.

        Args:
            proc: The processing module (e.g., a neural network) for the agent. Can be None or "default".
            proc_inputs: list of DataProps defining the expected inputs for processor (if None it will be guessed).
            proc_outputs: list of DataProps defining the expected outputs from processor (if None it will be guessed).
            proc_opts: A dictionary of options for the processor.
            behav: The HybridStateMachine that describes the agent's behavior.
            merge_flat_stream_labels: If True, merges flat stream labels across all owned streams.
            buffer_generated: If True, generated streams will be buffered.
            buffer_generated_by_others: If set to "one" or "last", streams generated by other agents will be buffered
                ("one" per peer or "all"). If set to "none", no buffering will happen (default).
        """

        # agent-related features
        self.behav = behav  # HSM that describes the agent behavior in the private/world net
        self.behav_lone_wolf = None  # HSM that describes the agent behavior in the public net (loaded below)
        self.behav_wildcards = {}
        self.proc = proc
        self.proc_inputs = proc_inputs
        self.proc_outputs = proc_outputs
        self.proc_opts = proc_opts
        self.proc_last_inputs = None
        self.proc_last_outputs = None
        self.proc_optional_inputs = None
        self.merge_flat_stream_labels = merge_flat_stream_labels
        self.buffer_generated = buffer_generated
        self.buffer_generated_by_others = buffer_generated_by_others

        assert self.buffer_generated_by_others in {"one", "all", "none"}, \
            "Param buffer_generated_by_others can be set to 'one', 'all', or 'none' only."

        # streams
        self.known_streams = {}  # all streams that are known to this agent
        self.owned_streams = {}  # the streams that are generated/offered by this agent
        self.env_streams = {}  # the owned streams that come from environmental sources (e.g., a camera)
        self.proc_streams = {}  # the owned streams that are generated by the agent's processor
        self.compat_in_streams = set()  # streams compatible with the processor input (dynamically set)
        self.compat_out_streams = set()  # streams compatible with the processor output (dynamically set)

        # agents, world masters, expected world masters
        self.all_agents = {}   # ID -> profile (all types of agent)
        self.public_agents = {}  # ID -> profile of lone wolves talking to this world in a public manner (profile)
        self.world_agents = {}  # ID -> profile of all agents living in this world (profile)
        self.world_masters = {}  # ID -> profile of all master-agents living in this world (profile)

        # status
        self.available = True  # it will be automatically set/changed during the agent's life
        self.is_world = False  # if this instance is about a world: it will be discovered at creation time

        # internal properties (automatically inferred while "living", not-user-defined)
        self._last_recorded_stream_num = 1
        self._last_recorded_stream_dict = None
        self._last_recording_stream_dict = None
        self._last_buffered_peer_id_to_info = {}

        # streams-related
        self._recipients = {}  # the peer IDs of the recipients of the next batch of direct messages
        self._preferred_streams = []  # list of preferred streams
        self._cur_preferred_stream = 0  # id of the current preferred stream from the list
        self._repeat = 1  # number of repetitions of the playlist

        # agent exchanges
        self._found_agents = set()  # peer IDs discovered
        self._valid_cmp_agents = set()  # agents for which the last evaluation was positive
        self._engaged_agents = set()
        self._agents_who_completed_what_they_were_asked = set()
        self._agents_who_were_asked = set()
        self._eval_results = {}
        self._last_ref_uuid = None

        # information inherited from the node that hosts this agent
        self._node_name = "unk"
        self._node_clock = None
        self._node_conn = None
        self._node_profile = None
        self._node_out_fcn = print
        self._node_ask_to_get_in_touch_fcn = None
        self._node_purge_fcn = None
        self._node_agents_waiting = None

        # checking
        assert (self.proc is None or
                (isinstance(self.proc, torch.nn.Module) or (isinstance(self.proc, str) and self.proc == "default"))), \
            "Invalid data processor: it must be either the string 'default' or a torch.nn.module"
        assert (self.behav is None or isinstance(self.behav, HybridStateMachine)), \
            "Invalid behavior: it must be either None or a HybridStateMachine"

        # filling (guessing) missing processor-related info (proc_inputs and proc_outputs)
        # and allocating a dummy processor if it was not specified (if None)
        AgentProcessorChecker(self)

        # the stream_hash of compatible streams for each data_props are stored in a set
        self.compat_in_streams = [set() for _ in range(len(self.proc_inputs))] \
            if self.proc_inputs is not None else None
        self.compat_out_streams = [set() for _ in range(len(self.proc_outputs))] \
            if self.proc_outputs is not None else None

        # loading default public HSM
        if hasattr(self, "do_gen"):  # trick to distinguish if this is an Agent or a World (both sons of this class)
            self.is_world = False

            # setting an empty HSM as default is not provided (private/world)
            if self.behav is None:
                self.behav = HybridStateMachine(self)
                self.behav.add_state("empty")

            self.behav_lone_wolf = HybridStateMachine(self)
            self.behav_lone_wolf.load(os.path.join(os.path.abspath(os.path.dirname(__file__)),
                                                   "library", "behaviors", "lone_wolf.json"))
        else:
            self.is_world = True

    def set_node_info(self, clock: Clock, conn: ConnectionPools, profile: NodeProfile,
                      out_fcn, ask_to_get_in_touch_fcn, purge_fcn, agents_waiting, print_level):
        """Set the required information from the node that hosts this agent.

        Args:
            clock: The global clock instance from the node.
            conn: The connection pool manager from the node.
            profile: The profile of the hosting node.
            out_fcn: The function to use for general output messages.
            ask_to_get_in_touch_fcn: The function to call to request getting in touch with another peer.
            purge_fcn: The function to call to purge (kill/disconnect) a connection.
            agents_waiting: Set of agents that connected to this node but have not been evaluated yet to be added.
        """

        # getting basic references
        self._node_name = profile.get_static_profile()['node_name']
        self._node_clock = clock
        self._node_profile = profile
        self._node_conn = conn
        self._node_out_fcn = out_fcn
        self._node_ask_to_get_in_touch_fcn = ask_to_get_in_touch_fcn
        self._node_purge_fcn = purge_fcn
        self._node_agents_waiting = agents_waiting

        # adding peer_id information into the already existing stream data (if any)
        # (initially marked with generic wildcards like <public_peer_id>, ...)
        net_hashes = list(self.known_streams.keys())
        for net_hash in net_hashes:
            if net_hash.startswith("<public_peer_id>") or net_hash.startswith("<private_peer_id>"):
                stream_dict = self.known_streams[net_hash]
                for stream_obj in stream_dict.values():
                    self.add_stream(stream_obj, owned=True)  # this will also re-add streams using the node clock
        self.remove_streams("<public_peer_id>", owned_too=True)
        self.remove_streams("<private_peer_id>", owned_too=True)

        # building combination of default roles (considering public, world_agent, world_master default roles), and
        # agent/world specific roles
        self.augment_roles()

        # creating streams associated to the processor output
        self.create_proc_output_streams(buffered=self.buffer_generated)

        # updating node profile by indicating the processor-related streams
        self.update_streams_in_profile()

        # print level
        AgentBasics.DEBUG = print_level > 1
        ConnectionPools.DEBUG = print_level > 1
        HybridStateMachine.DEBUG = print_level > 1

        # subscribing/creating our own pubsub
        return self.subscribe_to_pubsub_owned_streams()

    def augment_roles(self):
        """Combine default roles (public, world_agent, world_master, ...) with this agent/world specific roles."""

        # augmenting roles
        roles_not_to_be_augmented = {self.ROLE_PUBLIC, self.ROLE_WORLD_AGENT, self.ROLE_WORLD_MASTER}
        role_bits_to_str_original = {k: v for k, v in self.ROLE_BITS_TO_STR.items()}
        for role_int, role_str in role_bits_to_str_original.items():
            if role_int not in roles_not_to_be_augmented and "~" not in role_str:
                for role_base_int in {self.ROLE_WORLD_AGENT, self.ROLE_WORLD_MASTER}:
                    augmented_role_int = role_base_int | role_int
                    augmented_role_str = self.ROLE_BITS_TO_STR[role_base_int] + "~" + role_str
                    if augmented_role_str not in self.ROLE_STR_TO_BITS:
                        self.ROLE_STR_TO_BITS[augmented_role_str] = augmented_role_int
                        self.ROLE_BITS_TO_STR[augmented_role_int] = augmented_role_str

    def clear_world_related_data(self):
        """Destroy all the cached information that is about a world (useful when leaving a world)."""

        # mark as available (it could have been already set to true by some actions, of course)
        self.available = True

        # clear/reset
        self._preferred_streams = []
        self._cur_preferred_stream = 0
        self._repeat = 1
        self._engaged_agents = set()
        self._valid_cmp_agents = set()
        self._found_agents = set()
        self._eval_results = {}
        self._agents_who_completed_what_they_were_asked = set()
        self._agents_who_were_asked = set()
        self.__remove_all_world_private_streams()
        self.__remove_all_world_related_agents()
        self._node_conn.reset_rendezvous_tag()

    def out(self, msg: str):
        """Print a message to the console, if enabled at node level (it reuses the node-out-function).

        Args:
            msg: The message string to print.
        """
        self._node_out_fcn("{" + ("agent" if not self.is_world else "world") + "}" + " " + msg)

    def err(self, msg: str):
        """Print an error message to the console, if enabled at node level (it reuses the node-err-function).

        Args:
            msg: The error message string to print.
        """

        self.out("<ERROR> " + msg)

    def deb(self, msg: str):
        """Print an error message to the console, if debug is enabled for this agent (it reuses the agent-out-function).

        Args:
            msg: The error message string to print.
        """

        if AgentBasics.DEBUG:
            self.out("[DEBUG " + ("AGENT" if not self.is_world else "WORLD") + "] " + msg)

    def get_name(self):
        """Get the name of this agent/world (taken from the node profile)."""
        return self._node_name

    def get_current_role(self, return_int: bool = False, ignore_base_role: bool = True) -> str | int | None:
        if self.in_world():
            role_str = self._node_profile.get_dynamic_profile()['connections']['role']
            if ignore_base_role:
                role_str = role_str.split("~")[-1]
            if not return_int:
                return role_str
            else:
                return self.ROLE_STR_TO_BITS[role_str]
        else:
            return None

    def add_agent(self, peer_id: str, profile: NodeProfile) -> bool:
        """Add a new known agent.

        Args:
            peer_id: The unique identifier of the peer.
            profile: The NodeProfile object containing the peer's/agent's information.

        Returns:
            True if the agent was successfully added, False otherwise.
        """

        # if the agent was already there, we remove it and add it again (in case of changes)
        self.remove_agent(peer_id)  # it has no effects if the agent is not existing

        # guessing the type of agent to add (accordingly to the default roles shared by every agent)
        role = self._node_conn.get_role(peer_id)
        self.all_agents[peer_id] = profile
        if role & 1 == self.ROLE_PUBLIC:
            self.public_agents[peer_id] = profile
            public = True
        elif role & 3 == self.ROLE_WORLD_AGENT:
            self.world_agents[peer_id] = profile
            public = False
        elif role & 3 == self.ROLE_WORLD_MASTER:
            self.world_masters[peer_id] = profile
            public = False
        else:
            self.err(f"Cannot add agent with peer ID {peer_id} - unknown role: {role}")
            return False

        # check compatibility of the streams owned by the agent we are adding with our-agent's processor
        if self.proc_outputs is not None and self.proc_inputs is not None:

            # check compatibility of the environmental streams of the agent we are adding with our-agent's processor
            environmental_streams = profile.get_dynamic_profile()['streams']
            if (environmental_streams is not None and
                    not self.add_compatible_streams(peer_id, environmental_streams,
                                                    buffered=False, public=public)):  # this will also "add" the stream
                return False

            # check compatibility of the generated streams of the agent we are adding with our-agent's processor
            proc_streams = profile.get_dynamic_profile()['proc_outputs']
            if (proc_streams is not None and
                    not self.add_compatible_streams(peer_id, profile.get_dynamic_profile()['proc_outputs'],
                                                    buffered=False, public=public)):  # this will also "add" the stream
                return False

        self.out(f"Successfully added agent with peer ID {peer_id}")
        return True

    def remove_agent(self, peer_id: str):
        """Remove an agent.

        Args:
            peer_id: The unique identifier of the peer to remove.
        """
        if peer_id in self.all_agents:

            # removing from agent list
            del self.all_agents[peer_id]
            if peer_id in self.world_agents:
                del self.world_agents[peer_id]
            elif peer_id in self.world_masters:
                del self.world_masters[peer_id]
            elif peer_id in self.public_agents:
                del self.public_agents[peer_id]

            # clearing from the list of processor-input-compatible-streams
            if self.compat_in_streams is not None:
                for i, _ in enumerate(self.compat_in_streams):
                    to_remove = []
                    for net_hash_name in self.compat_in_streams[i]:
                        if DataProps.peer_id_from_net_hash(net_hash_name[0]) == peer_id:
                            to_remove.append(net_hash_name)
                    for net_hash_name in to_remove:
                        self.compat_in_streams[i].remove(net_hash_name)

            # clearing from the list of processor-output-compatible-streams
            if self.compat_out_streams is not None:
                for i, _ in enumerate(self.compat_out_streams):
                    to_remove = []
                    for net_hash_name in self.compat_out_streams[i]:
                        if DataProps.peer_id_from_net_hash(net_hash_name[0]) == peer_id:
                            to_remove.append(net_hash_name)
                    for net_hash_name in to_remove:
                        self.compat_out_streams[i].remove(net_hash_name)

            # clearing streams owned by the removed agent from the list of known streams
            self.remove_streams(peer_id)

            # removing from engaged agents and the other status variables
            self._engaged_agents.discard(peer_id)   # only if present
            self._agents_who_were_asked.discard(peer_id)  # only if present
            self._agents_who_completed_what_they_were_asked.discard(peer_id)  # only if present
            self._found_agents.discard(peer_id)  # only if present
            self._valid_cmp_agents.discard(peer_id)  # only if present
            self._engaged_agents.discard(peer_id)  # only if present
            self.available = len(self._engaged_agents) == 0
            if peer_id in self._eval_results:
                del self._eval_results[peer_id]   # only if present
            if peer_id in self._last_buffered_peer_id_to_info:
                del self._last_buffered_peer_id_to_info[peer_id]   # only if present
            self.out(f"Successfully removed agent with peer ID {peer_id}")

    def remove_all_agents(self):
        """Remove all known agents."""

        # clearing all agents
        self.all_agents = {}
        self.public_agents = {}
        self.world_masters = {}
        self.world_agents = {}

        # clearing the list of processor-output-compatible-streams
        if self.compat_in_streams is not None and self.proc_inputs is not None:
            self.compat_in_streams = [set() for _ in range(len(self.proc_inputs))]
        if self.compat_out_streams is not None and self.proc_outputs is not None:
            self.compat_out_streams = [set() for _ in range(len(self.proc_outputs))]

        # clearing the list of known streams (not our own streams!)
        self.remove_all_streams(owned_too=False)
        self.out(f"Successfully removed all agents")

    def add_behav_wildcard(self, wildcard_from: str, wildcard_to: object):
        self.behav_wildcards[wildcard_from] = wildcard_to

    def add_stream(self, stream: DataStream, owned: bool = True, net_hash: str | None = None) -> dict[str, DataStream]:
        """Add a new stream to the set of known streams.

        Args:
            stream: The DataStream object to add.
            owned: If True, the streams are considered owned by this agent.
            net_hash: Optional network hash for the streams. If None, it will be generated.

        Returns:
            A dictionary containing the added stream and the possibly already present streams belonging to the same
            group (stream name -> stream object).
        """

        # forcing clock
        stream.clock = self._node_clock

        # stream net hash
        if net_hash is None:
            public_peer_id, private_peer_id = self.get_peer_ids()
            peer_id = public_peer_id if stream.is_public() else private_peer_id
            net_hash = stream.net_hash(peer_id)

        # adding the new stream
        if net_hash not in self.known_streams:
            self.known_streams[net_hash] = {}
        else:
            for _stream in self.known_streams[net_hash].values():
                public = _stream.get_props().is_public()
                pubsub = _stream.get_props().is_pubsub()
                if public and not stream.get_props().is_public():
                    self.err(f"Cannot add a stream to a group with different properties (public): "
                             f"hash: {net_hash}, name: {stream.get_props().get_name()}, "
                             f"public: {stream.get_props().is_public()}")
                    return {}
                if pubsub and not stream.get_props().is_pubsub():
                    self.err(f"Cannot add a stream to a group with different properties (pubsub): "
                             f"hash: {net_hash}, name: {stream.get_props().get_name()}, "
                             f"public: {stream.get_props().is_public()}")
                    return {}
                break
        self.known_streams[net_hash][stream.get_props().get_name()] = stream

        if owned:

            # adding an 'owned' processor output stream (i.e., the stream coming from OUR OWN processor)
            is_proc_outputs_stream = False
            if self.proc_outputs is not None:
                proc_outputs_name_and_group = set()
                for props in self.proc_outputs:
                    proc_outputs_name_and_group.add((props.get_name(), props.get_group()))
                if (stream.get_props().get_name(), stream.get_props().get_group()) in proc_outputs_name_and_group:
                    if net_hash not in self.proc_streams:
                        self.proc_streams[net_hash] = {}
                    self.proc_streams[net_hash][stream.get_props().get_name()] = stream
                    is_proc_outputs_stream = True

            if net_hash not in self.owned_streams:
                self.owned_streams[net_hash] = {}
            self.owned_streams[net_hash][stream.get_props().get_name()] = stream

            if not is_proc_outputs_stream:
                if net_hash not in self.env_streams:
                    self.env_streams[net_hash] = {}
                self.env_streams[net_hash][stream.get_props().get_name()] = stream

        # adding empty recipient slot
        if net_hash not in self._recipients:
            self._recipients[net_hash] = None

        # if needed, merging descriptor labels (attribute labels) and sharing them with all streams
        if self.merge_flat_stream_labels:
            self.merge_flat_data_stream_props()

        return self.known_streams[net_hash]

    def add_streams(self, streams: list[DataStream], owned: bool = True, net_hash: str | None = None) \
            -> list[dict[str, DataStream]]:
        """Add a list of new streams to this environment.

        Args:
            streams: A list of DataStream objects to add.
            owned: If True, the streams are considered owned by this agent.
            net_hash: Optional network hash for the streams. If None, it will be generated for each.

        Returns:
            A list of dictionaries (it could be empty in case of issues), where each dictionary is what
            is returned by add_stream().
        """
        # adding the new stream
        ret = []
        for stream in streams:
            stream_dict = self.add_stream(stream, owned, net_hash)
            if len(stream_dict) == 0:
                return []
            ret.append(stream_dict)
        return ret

    def remove_streams(self, peer_id: str, name: str | None = None, owned_too: bool = False):
        """Remove a known stream.

        Args:
            peer_id: The hash of each stream included the peer ID of the owner, so this is the peer ID associated with
                the stream(s) to remove.
            name: The optional name of the stream to remove. If None, all streams with this peer_id are removed.
            owned_too: If True, also removes streams from the owned stream dict (so also environmental and processor).
        """

        # identifying what to remove
        to_remove = []
        for net_hash in self.known_streams.keys():
            if DataProps.peer_id_from_net_hash(net_hash) == peer_id:
                for _name, _stream in self.known_streams[net_hash].items():
                    if name is None or name == _name:
                        to_remove.append((net_hash, _name))

        # removing
        for (net_hash, name) in to_remove:
            if not owned_too and net_hash in self.owned_streams:
                continue

            del self.known_streams[net_hash][name]
            if len(self.known_streams[net_hash]) == 0:
                del self.known_streams[net_hash]

            # unsubscribing to pubsub
            if DataProps.is_pubsub_from_net_hash(net_hash):
                if peer_id != "<private_peer_id>" and peer_id != "<public_peer_id>":
                    if not self._node_conn.unsubscribe(peer_id, channel=net_hash):
                        self.err(f"Failed in unsubscribing from pubsub, peer_id: {peer_id}, channel: {net_hash}")
                    else:
                        self.out(f"Successfully unsubscribed from pubsub, peer_id: {peer_id}, channel: {net_hash}")

            # removing all the owned streams (environment and processor streams are of course "owned")
            if net_hash in self.owned_streams:
                if name in self.owned_streams[net_hash]:
                    del self.owned_streams[net_hash][name]
                    if len(self.owned_streams[net_hash]) == 0:
                        del self.owned_streams[net_hash]
            if net_hash in self.env_streams:
                if name in self.env_streams[net_hash]:
                    del self.env_streams[net_hash][name]
                    if len(self.env_streams[net_hash]) == 0:
                        del self.env_streams[net_hash]
            if net_hash in self.proc_streams:
                if name in self.proc_streams[net_hash]:
                    del self.proc_streams[net_hash][name]
                    if len(self.proc_streams[net_hash]) == 0:
                        del self.proc_streams[net_hash]
            self.out(f"Successfully removed known stream with network hash {net_hash}, stream name: {name}")

    def remove_all_streams(self, owned_too: bool = False):
        """Remove all not-owned streams.

        Args:
            owned_too: If True, also removes the owned streams of this agent (so also environmental and processor ones).
        """

        if not owned_too:
            self.known_streams = {k: v for k, v in self.owned_streams}
        else:
            self.known_streams = {}
            self.owned_streams = {}
            self.env_streams = {}
            self.proc_streams = {}
        self.out(f"Successfully removed all streams!")

    def find_streams(self, peer_id: str, name_or_group: str | None = None) -> dict[str, dict[str, DataStream]]:
        """Find streams associated with a given peer ID and optionally by name or group.

        Args:
            peer_id: The peer ID of the (owner of the) streams to find.
            name_or_group: Optional name or group of the streams to find.

        Returns:
            A dictionary where keys are network hashes and values are dictionaries of streams
            (stream name to DataStream object) matching the criteria.
        """
        ret = {}
        for net_hash, streams_dict in self.known_streams.items():
            _peer_id = DataStream.peer_id_from_net_hash(net_hash)
            _name_or_group = DataStream.name_or_group_from_net_hash(net_hash)
            if peer_id == _peer_id:
                if name_or_group is None or name_or_group == _name_or_group:
                    ret[net_hash] = streams_dict
                else:
                    for _name, _stream in streams_dict.items():
                        if name_or_group == _name:
                            if net_hash not in ret:
                                ret[net_hash] = {}
                            ret[net_hash][name_or_group] = _stream
        return ret

    def merge_flat_data_stream_props(self):
        """Merge the labels of the descriptor components, across all streams, sharing them."""

        # set of pivot labels
        superset_labels = []

        # checking the whole list of streams, but considering only the ones with generic data, flat, and labels
        considered_streams = []

        for stream_dict in self.owned_streams.values():
            for stream in stream_dict.values():

                # skipping not flat, or not generic, or unlabeled streams
                if not stream.props.is_flat_tensor_with_labels():
                    continue

                # saving list of considered streams
                considered_streams.append(stream)

                # adding the current stream-labels to the pivot labels
                for label in stream.props.tensor_labels:
                    if label not in superset_labels:
                        superset_labels.append(label)

        # telling each stream in which positions their labels fall, given the pivot labels
        for stream in considered_streams:

            # in the case of BufferedDataStream, we have to update the data buffer by clearing previously applied
            # adaptation first (I know it looks similar to what is done below, but we must clear first!)
            if isinstance(stream, BufferedDataStream):
                for i, (data, data_tag) in enumerate(stream.data_buffer):
                    stream.data_buffer[i] = (stream.props.clear_label_adaptation(data), data_tag)

            # updating labels
            stream.props.tensor_labels.interleave_with(superset_labels)

            # in the case of BufferedDataStream, we have to update the data buffer with the new labels
            if isinstance(stream, BufferedDataStream):
                for i, (data, data_tag) in enumerate(stream.data_buffer):
                    stream.data_buffer[i] = (stream.props.adapt_tensor_to_tensor_labels(data), data_tag)

    def user_stream_hash_to_net_hash(self, user_stream_hash: str) -> str | None:
        """Converts a user-defined stream hash (peer_id:name_or_group) to a network hash
        (peer_id::dm:... or peer_id::ps:name_or_group) by searching the known hashes in the known streams.

        Args:
            user_stream_hash: The user-defined stream hash string (peer_id:name_or_group).

        Returns:
            The corresponding network hash string (peer_id::dm:... or peer_id::ps:name_or_group), or None if not found.
        """
        components = user_stream_hash.split(":")
        peer_id = components[0]
        name_or_group = components[-1]
        for net_hash in self.known_streams.keys():
            _peer_id = DataStream.peer_id_from_net_hash(net_hash)
            _name_or_group = DataStream.name_or_group_from_net_hash(net_hash)
            if _peer_id == peer_id and _name_or_group == name_or_group:
                return net_hash
        return None

    def create_proc_output_streams(self, buffered: bool = False):
        """Creates the processor output streams based on the `proc_outputs` defined for the agent.

        Args:
            buffered: If True, the created streams will be of type BufferedDataStream.
        """

        # adding generated streams (grouped together), passing the node clock
        if self.proc_outputs is not None:
            for i, procs in enumerate(self.proc_outputs):
                procs.set_group("processor")  # adding default group info, forced, do not change this!

                # creating the streams
                for props in procs.props:
                    if not buffered:
                        stream = DataStream(props=props.clone(), clock=self._node_clock)
                    else:
                        stream = BufferedDataStream(props=props.clone(), clock=self._node_clock)

                    self.add_stream(stream, owned=True)

    def add_compatible_streams(self, peer_id: str,
                               streams_in_profile: list[DataProps], buffered: bool = False,
                               add_all: bool = False, public: bool = True) -> bool:
        """Add to the list of processor-compatible-streams those streams provided as arguments that are actually
        found to be compatible with the processor (if they are pubsub, it also subscribes to them).

        Args:
            peer_id: The peer ID of the agent providing the streams.
            streams_in_profile: A list of DataProps objects representing the streams from the peer's profile.
            buffered: If True, the added streams will be of type BufferedDataStream.
            add_all: If True, all streams from the profile are added, regardless of processor compatibility.
            public: Consider public streams only (or private streams only).

        Returns:
            True if compatible streams were successfully added and subscribed to, False otherwise.
        """
        added_streams = []

        if add_all:

            # this is the case in which we add all streams, storing all pairs (DataProps, net_hash)
            for j in streams_in_profile:
                jj = DataProps.from_dict(j)
                if public == jj.is_public():
                    net_hash = jj.net_hash(peer_id)
                    added_streams.append((jj, net_hash))
        else:

            # this is the case in which a processor is present, hence storing pairs (DataProps, net_hash)
            # of the found compatible streams
            added_net_hash_to_prop_name = {}

            # find streams that are compatible with our 'proc_inputs'
            for i, in_proc in enumerate(self.proc_inputs):
                for j in streams_in_profile:
                    jj = DataProps.from_dict(j)
                    if public == jj.is_public() and in_proc.is_compatible(jj):
                        net_hash = jj.net_hash(peer_id)

                        if net_hash not in added_net_hash_to_prop_name:
                            added_net_hash_to_prop_name[net_hash] = set()
                        if jj.name not in added_net_hash_to_prop_name[net_hash]:
                            added_net_hash_to_prop_name[net_hash].add(jj.name)
                            added_streams.append((jj, net_hash))

                        # saving the position in the proc_input list
                        self.compat_in_streams[i].add((net_hash, jj.get_name()))

            # find streams that are compatible with our 'proc_outputs'
            has_cross_entropy = []
            if 'losses' in self.proc_opts:
                for i in range(0, len(self.proc_outputs)):
                    if self.proc_opts['losses'][i] is not None and \
                            (self.proc_opts['losses'][i] == torch.nn.functional.cross_entropy or
                             isinstance(self.proc_opts['losses'][i], torch.nn.CrossEntropyLoss) or
                             "cross_entropy" in self.proc_opts['losses'][i].__name__):
                        has_cross_entropy.append(True)
                    else:
                        has_cross_entropy.append(False)

            for i, out_proc in enumerate(self.proc_outputs):
                for j in streams_in_profile:
                    jj = DataProps.from_dict(j)
                    if (public == jj.is_public() and
                            (out_proc.is_compatible(jj) or (jj.is_tensor_target_id() and has_cross_entropy[i]))):
                        net_hash = jj.net_hash(peer_id)

                        if net_hash not in added_net_hash_to_prop_name:
                            added_net_hash_to_prop_name[net_hash] = set()
                        if jj.name not in added_net_hash_to_prop_name[net_hash]:
                            added_net_hash_to_prop_name[net_hash].add(jj.name)
                            added_streams.append((jj, net_hash))

                        # saving the position in the proc_output list
                        self.compat_out_streams[i].add((net_hash, jj.get_name()))

        net_hashes_to_subscribe = set()

        # for each compatible stream found...
        for (props, net_hash) in added_streams:

            # check if it is a new stream or a data stream to add to an already known stream
            already_known_stream = net_hash in self.known_streams

            # creating the stream object
            if not buffered:
                stream = DataStream(props=props.clone(), clock=self._node_clock)
            else:
                stream = BufferedDataStream(props=props.clone(), clock=self._node_clock)

            # add the data stream to the list of known streams
            # if the stream already exists it will be overwritten (which is fine in case of changes)
            self.add_stream(stream, owned=False, net_hash=net_hash)

            # if the stream is over PubSub, and we are not already subscribed, we will subscribe
            if props.is_pubsub() and not already_known_stream:
                net_hashes_to_subscribe.add(net_hash)

        # opening PubSubs
        for net_hash in net_hashes_to_subscribe:
            self.out(f"Opening channel for the not-owned but processor-compatible stream {net_hash}")
            if not self._node_conn.subscribe(peer_id, channel=net_hash):
                self.err(f"Error subscribing to {net_hash}")
                return False

        return True

    def subscribe_to_pubsub_owned_streams(self) -> bool:
        """Subscribes to all owned streams that are marked as PubSub.

        Returns:
            True if all subscriptions were successful, False otherwise.
        """

        # opening channels for all the (groups of) owned streams (generated and not)
        for net_hash in self.owned_streams.keys():
            is_pubsub = DataStream.is_pubsub_from_net_hash(net_hash)

            if is_pubsub:
                self.out(f"Opening channel for the owned stream {net_hash}")
                peer_id = DataStream.peer_id_from_net_hash(net_hash)  # guessing peer ID from the net hash

                if not self._node_conn.subscribe(peer_id, channel=net_hash):
                    self.err(f"Cannot open a channel for owned stream hash {net_hash}")
                    return False
        return True

    def update_streams_in_profile(self):
        """Updates the agent's profile with information about its owned (environmental and processor) streams."""

        # filling the information about the streams that can be generated and handled
        dynamic_profile = self._node_profile.get_dynamic_profile()
        if hasattr(self, 'proc_outputs') and hasattr(self, 'proc_inputs'):
            dynamic_profile['proc_outputs'] = \
                [dct for d in self.proc_outputs for dct in d.to_list_of_dicts()]  # list of dict of DataProp
            dynamic_profile['proc_inputs'] = \
                [dct for d in self.proc_inputs for dct in d.to_list_of_dicts()]  # list of dict of DataProp

        # adding the list of locally-created ("environmental") streams to the profile
        list_of_props = []
        public_peer_id, private_peer_id = self.get_peer_ids()
        for net_hash, streams_dict in self.known_streams.items():
            if net_hash not in self.proc_streams.keys():
                if (DataProps.peer_id_from_net_hash(net_hash) == public_peer_id or
                        DataProps.peer_id_from_net_hash(net_hash) == private_peer_id):
                    for stream in streams_dict.values():
                        list_of_props.append(stream.get_props().to_dict())  # DataProp
        if len(list_of_props) > 0:
            dynamic_profile['streams'] = list_of_props

    def send_profile_to_all(self):
        """Sends the agent's profile to all known agents."""

        for peer_id in self.all_agents.keys():
            self.out(f"Sending profile to {peer_id}")
            if not self._node_conn.send(peer_id, channel_trail=None,
                                        content=self._node_profile.get_all_profile(),
                                        content_type=Msg.PROFILE):
                self.err("Failed to send profile, removing (disconnecting) " + peer_id)
                self.remove_agent(peer_id)

    def generate(self, input_net_hashes: list[str] | None, inputs: list[str | torch.Tensor | Image] | None = None,
                 first: bool = False, last: bool = False, ref_uuid: str | None = None) -> (
            tuple[tuple[torch.Tensor] | None, int]):
        """Generate new signals.

        Args:
            input_net_hashes: A list of network hashes to be considered as input streams (they will be sub-selected).
            inputs: A list of data to be directly provided as input to the processor (if not None, input_net_hashes is
                ignored).
            first: If True, indicates this is the first generation call in a sequence.
            last: If True, indicates this is the last generation call in a sequence.
            ref_uuid: An optional UUID to match against input stream UUIDs (it can be None).

        Returns:
            A tuple containing:
                - A tuple of torch.Tensor objects representing the generated output, or None if generation failed.
                - An integer representing a data tag or status.
        """

        # preparing processor input
        if inputs is None:
            inputs = [None] * len(self.proc_inputs)
            matched = set()
            data_tag = None

            # checking UUIDs and searching the provided input streams: we look to match them with the processor input
            for net_hash in input_net_hashes:
                stream_dict = self.known_streams[net_hash]
                for stream_name, stream in stream_dict.items():

                    # checking the UUID in our known streams, comparing it with the UUID provided as input:
                    # if they are not compatible, we don't generate at all
                    if ref_uuid is not None and stream.get_uuid(expected=False) != ref_uuid:
                        self.deb(f"[generate] The stream UUID ({stream.get_uuid(expected=False)}, expected: "
                                 f"{stream.get_uuid(expected=True)}) is not the one we were "
                                 f"looking for ({ref_uuid}), returning None")
                        return None, -1

                    # matching the currently checked input stream with one of the processor inputs
                    stream_sample = None
                    for i in range(len(self.proc_inputs)):

                        # if the current input stream is compatible with the i-th input slot...
                        if (net_hash, stream_name) in self.compat_in_streams[i]:

                            # if the current input stream was already assigned to another input slot
                            # (different from "i") we skip the generation
                            if (net_hash, stream_name) in matched:
                                self.err("Cannot generate: ambiguous input streams provided "
                                         "(they can match multiple processor inputs)")
                                return None, -1

                            # found a valid assignment: getting stream sample
                            self.deb(f"[generate] Setting the {i}-th network input to stream with "
                                     f"net_hash: {net_hash}, name: {stream_name}")
                            if stream_sample is None:
                                stream_sample = stream.get(requested_by="generate")
                                if stream_sample is None:  # if there are no samples in this stream, we cannot generate
                                    self.err(
                                        f"Cannot generate: got nothing (None) from what we would provide to the {i}-th "
                                        f"input position of the processor")
                                    return None, -1

                            # found a valid assignment: associating it to the i-th input slot
                            try:
                                inputs[i] = self.proc_inputs[i].check_and_preprocess(stream_sample,
                                                                                     device=self.proc.device)
                            except Exception as e:
                                self.err(f"Error while checking and preprocessing the {i}-th input\n{e}")

                            # found a valid assignment: saving match
                            matched.add((net_hash, stream_name))

                            # if all the inputs share the same data tag, we will return it,
                            # otherwise we set it at -1 (meaning no tag)
                            if data_tag is None:
                                data_tag = stream.get_tag()
                            elif data_tag != stream.get_tag():
                                data_tag = -1

                            if AgentBasics.DEBUG:
                                if stream.props.is_text():
                                    self.deb(f"[generate] Input of the network: {stream_sample}")

                            break

            # checking if we were able to match some data for each input slot of the network (processor)
            for i in range(len(self.proc_inputs)):
                if inputs[i] is None:
                    if self.proc_optional_inputs[i]["has_default"]:
                        inputs[i] = self.proc_optional_inputs[i]["default_value"]
                    else:
                        self.err(
                            f"Cannot generate: couldn't find a valid input for the "
                            f"{i}-th input position of the processor")
                        return None, -1
        else:
            data_tag = -1

        if AgentBasics.DEBUG:
            self.deb(f"[generate] input shapes: {[x.shape for x in inputs if isinstance(x, torch.Tensor)]}")
            self.deb(f"[generate] input data tag: {data_tag}")

        # calling processor (inference) passing the collected inputs
        inputs = self.proc_callback_inputs(inputs)
        try:
            outputs = self.proc(*inputs, first=first, last=last)

            # ensuring the output is a tuple, even if composed by a single tensor
            if not isinstance(outputs, tuple):
                outputs = (outputs, )
        except Exception as e:
            self.err(f"Error while calling the processor\n{e}")
            outputs = None
        outputs = self.proc_callback_outputs(outputs)

        # saving
        self._last_ref_uuid = ref_uuid

        if AgentBasics.DEBUG:
            for net_hash, stream_dict in self.proc_streams.items():
                for stream in stream_dict.values():
                    if stream.props.is_tensor():
                        if outputs is not None:
                            self.deb(f"[generate] text outputs: "
                                     f"{[str(stream.props.to_text(x)) for i, x in enumerate(outputs)]}")
                        break
            if outputs is not None:
                self.deb(f"[generate] output shapes: {[x.shape for x in outputs if isinstance(x, torch.Tensor)]}")

        return outputs, data_tag

    def learn_generate(self,
                       outputs: tuple[torch.Tensor],
                       targets_net_hashes: list[str] | None) -> tuple[list[float] | None, list[float] | None]:
        """Learn (i.e., update model params) by matching the given processor outputs with a set of targets (if any).

        Args:
            outputs: A tuple of torch.Tensor representing the outputs generated by the agent's processor.
            targets_net_hashes: An optional list of network hashes identifying the streams
                                from which target data should be retrieved for learning.
                                If None, losses are evaluated without explicit targets.

        Returns:
            A tuple containing:
            - A list of float values representing the individual loss values for each output.
              Returns None if targets are specified but cannot be found.
            - A list of integers representing the data tags of the given target streams (None if no targets were given).
        """

        # cannot learn without optimizer and losses
        if (self.proc_opts['optimizer'] is None or self.proc_opts['losses'] is None or
                len(self.proc_opts['losses']) == 0):
            return None, None

        # matching targets with the output slots of the processor
        at_least_one_target_found = False
        if targets_net_hashes is not None:
            targets = [None] * len(self.proc_outputs)
            matched = set()
            data_tags = [-1] * len(self.proc_outputs)

            # for each target stream group...
            for net_hash in targets_net_hashes:
                stream_dict = self.known_streams[net_hash]

                # for each stream of the current target group....
                for stream_name, stream in stream_dict.items():
                    stream_sample = None

                    # for each output slot of our processor... (index "i")
                    for i in range(len(self.proc_outputs)):

                        # check if the i-th target was already assigned or if the i-th output is not a tensor
                        if targets[i] is not None or not isinstance(outputs[i], torch.Tensor):
                            continue

                        # if the target stream is compatible with the i-th output of the processor...
                        if (net_hash, stream_name) in self.compat_out_streams[i]:

                            # if the current target was already assigned to another output slot (different from "i)"
                            # we skip learning
                            if (net_hash, stream_name) in matched:
                                self.err("Cannot generate: ambiguous target streams provided "
                                         "(they can match multiple processor outputs)")
                                return None, None

                            # found a valid assignment: getting stream sample
                            if stream_sample is None:
                                stream_sample = stream.get(requested_by="learn_generate")
                                if stream_sample is None:
                                    return None, None

                            # found a valid assignment: associating target to the i-th output slot
                            try:
                                targets[i] = self.proc_outputs[i].check_and_preprocess(stream_sample,
                                                                                       allow_class_ids=True,
                                                                                       targets=True,
                                                                                       device=self.proc.device)
                            except Exception as e:
                                self.err(f"Error while checking and preprocessing the {i}-th targets\n{e}")

                            # found a valid assignment: saving match
                            matched.add((net_hash, stream_name))

                            # saving tag
                            data_tags[i] = stream.get_tag()

                            # confirming
                            at_least_one_target_found = True

                            if AgentBasics.DEBUG:
                                if stream.props.is_tensor():
                                    self.deb("[generate] Target of the network: " +
                                             str(stream.props.to_text(targets[i])))
                                elif stream.props.is_text():
                                    self.deb("[generate] Target of the network: " +
                                             stream_sample)
                            break

            # if no targets were matched, we skip learning
            if not at_least_one_target_found:
                self.err(f"Cannot learn: cannot find a valid target for any output positions of the processor")
                return None, None
        else:

            # if no targets were provided, it is expected to be the case of fully unsupervised learning
            data_tags = None
            targets = None

        # retrieving custom elements from the option dictionary
        loss_functions: list = self.proc_opts['losses']
        optimizer: torch.optim.optimizer.Optimizer | None = self.proc_opts['optimizer']

        # evaluating loss function(s), one for each processor output slot (they are set to 0. if no targets are there)
        if targets_net_hashes is not None:

            # supervised or partly supervised learning
            loss_values = [loss_fcn(outputs[i], targets[i]) if targets[i] is not None else
                           torch.tensor(0., device=self.proc.device)
                           for i, loss_fcn in enumerate(loss_functions)]
            loss = torch.stack(loss_values).sum()  # sum of losses
        else:

            # unsupervised learning
            loss_values = [loss_fcn(outputs[i]) for i, loss_fcn in enumerate(loss_functions)]
            loss = torch.stack(loss_values).sum()  # sum of losses

        # learning step
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # teaching (for autoregressive models, expected to have attribute "y")
        if hasattr(self.proc, 'y'):
            self.proc.y = targets[0]

        # returning a list of float values and the data tags of the targets
        return [loss_value.item() for loss_value in loss_values], data_tags

    def behave(self):
        """Behave in the current environment, calling the state-machines of the public and private networks."""

        if self.in_world():
            self.out("Behaving (world)...")
            if self.behav is None:
                self.err("No behaviour specified")
            else:
                self.behav_lone_wolf.enable(False)
                self.behav.enable(True)
                self.behav.act()
                self.behav.enable(False)

        self.out("Behaving (public)...")
        if self.behav_lone_wolf is None:
            self.err("No behaviour specified")
        else:
            self.behav.enable(False)
            self.behav_lone_wolf.enable(True)
            self.behav_lone_wolf.act()
            self.behav_lone_wolf.enable(False)

    def learn_behave(self, state: int, last_action: int, prev_state: int) -> int:
        """Learn to behave in the current environment."""
        pass

    def get_peer_ids(self):
        """Retrieve the public and private peer IDs of the agent, from the underlying node's dynamic profile.

        Returns:
            A tuple containing the public peer ID and the private peer ID.
            If either ID is not available, a placeholder string is returned <public_peer_id>, <private_peer_id>.
        """
        public_peer_id = None
        private_peer_id = None
        if self._node_profile is not None:
            dynamic_profile = self._node_profile.get_dynamic_profile()
            public_peer_id = dynamic_profile['peer_id']  # public
            private_peer_id = dynamic_profile['private_peer_id']  # private
        public_peer_id = '<public_peer_id>' if public_peer_id is None else public_peer_id
        private_peer_id = '<private_peer_id>' if private_peer_id is None else private_peer_id
        return public_peer_id, private_peer_id

    def evaluate_profile(self, role: int, profile: NodeProfile) -> bool:
        """Evaluate if a given profile is valid for this agent based on its role. It helps in identifying and filtering
         out invalid or 'cheating' profiles.

        Args:
            role: The expected integer role (e.g., ROLE_PUBLIC, ROLE_WORLD_MASTER) for the profile.
            profile: The NodeProfile object to be evaluated.

        Returns:
            True if the profile is considered valid for the specified role, False otherwise.
        """

        # if the role in the profile is not the provided role, a profile-cheater was found
        if self.ROLE_STR_TO_BITS[profile.get_dynamic_profile()['connections']['role']] != role:
            self.out(f"Cheater found: "
                     f"{profile.get_dynamic_profile()['connections']['role']} != {self.ROLE_BITS_TO_STR[role]}")
            return False  # cheater found

        # these are just examples: you are expected to reimplement this method in your custom agent file
        if (role & 1 == self.ROLE_PUBLIC and
                profile.get_dynamic_profile()['guessed_location'] == 'Some Dummy Location, Just An Example Here'):
            return False
        elif (role & 3 == self.ROLE_WORLD_MASTER and
                profile.get_dynamic_profile()['guessed_location'] == 'Some Other Location, Just Another Example Here'):
            return False
        else:
            return True

    def accept_new_role(self, role: int, default_behav: str | None):
        """Set the agent's role and optionally load a default behavior (private/world behaviour).

        Args:
            role: The integer role to assign to the agent (e.g., ROLE_PUBLIC, ROLE_WORLD_MASTER).
            default_behav: An optional string path to a JSON file defining a default HybridStateMachine behavior.
                           If None or empty, no default behavior is loaded.
        """
        self._node_profile.get_dynamic_profile()['connections']['role'] = self.ROLE_BITS_TO_STR[role]

        if default_behav is not None and len(default_behav) > 0:
            default_behav_hsm = HybridStateMachine(self)
            default_behav_hsm.load(default_behav)
            self.behav = HybridStateMachine(self)
            self.behav.include(default_behav_hsm, make_a_copy=True)

    def in_world(self):
        """Check if the agent is currently operating within a 'world'.

        Returns:
            True if the agent is in a world, False otherwise.
        """
        if self._node_profile is not None:
            return self.ROLE_STR_TO_BITS[self._node_profile.get_dynamic_profile()['connections']['role']] & 1 == 1
        else:
            return False

    def behaving_in_world(self):
        return self.behav.is_enabled()

    def get_stream_sample(self, net_hash: str, sample_dict: dict[str, dict[str, torch.Tensor | None | int | str]]):
        """Receive and process stream samples that were provided by another agent.

        Args:
            net_hash: The network hash identifying the source of the stream samples.
            sample_dict: A dictionary where keys are stream names and values are dictionaries
                         containing 'data', 'data_tag', and 'data_uuid' for each sample.

        Returns:
            True if the stream samples were successfully processed and stored, False otherwise
            (e.g., if the stream is unknown, not compatible, or data is None/stale).
        """

        # let's be sure that the net hash is converted from the user's perspective to the one of the code here
        net_hash = DataProps.normalize_net_hash(net_hash)

        self.out(f"Got a stream sample from {net_hash}...")

        if net_hash in self.known_streams:
            self.out(f"Parsing samples from {net_hash}...")

            for name, data_and_tag_and_uuid in sample_dict.items():
                data, data_tag, data_uuid = (data_and_tag_and_uuid['data'],
                                             data_and_tag_and_uuid['data_tag'],
                                             data_and_tag_and_uuid['data_uuid'])

                # - data must be not None
                # - the stream name must be known
                # - if the UUID associated to our local stream is the same of the data, then we check tag order
                # - if the UUID associated to our local stream is the expected one, we don't check tag order
                skip = data is None
                skip = skip or name not in self.known_streams[net_hash]
                skip = (skip or (self.known_streams[net_hash][name].get_uuid(expected=True) is not None and
                        data_uuid != self.known_streams[net_hash][name].get_uuid(expected=True)))
                skip = (skip or (self.known_streams[net_hash][name].get_uuid(expected=True) is None and
                        self.known_streams[net_hash][name].get_uuid(expected=False) is not None and
                        data_uuid != self.known_streams[net_hash][name].get_uuid(expected=False)))
                skip = (skip or (self.known_streams[net_hash][name].get_uuid(expected=True) is None and
                        self.known_streams[net_hash][name].get_uuid(expected=False) is not None and
                        data_uuid == self.known_streams[net_hash][name].get_uuid(expected=False) and
                        data_tag <= self.known_streams[net_hash][name].get_tag()))

                # if we sample can be accepted...
                if not skip:
                    self.out(f"Getting sample named {name}, data_tag {data_tag}, data_uuid {data_uuid}...")
                    self.deb(f"[get_stream_sample] self.known_streams[net_hash][name].get_tag()="
                             f"{self.known_streams[net_hash][name].get_tag()}, "
                             f"stream.get_uuid(expected=False)="
                             f"{self.known_streams[net_hash][name].get_uuid(expected=False)}, "
                             f"stream.get_uuid(expected=True)="
                             f"{self.known_streams[net_hash][name].get_uuid(expected=True)}")

                    # saving the data sample on the known stream objects
                    self.known_streams[net_hash][name].set(data, data_tag)

                    # if the local stream was expecting data with a certain UUID, and we got it ...
                    # OR
                    # if the local stream was not expecting anything and was also not set to any UUID, and we got data
                    # with some UUID ...
                    # THEN
                    # we clear expectations and set the current UUID to the one of the data.
                    # (the second part of the OR above is the case of data that arrives before an action request,
                    # since action requests set expectations only)
                    if ((self.known_streams[net_hash][name].get_uuid(expected=True) is not None and
                         data_uuid == self.known_streams[net_hash][name].get_uuid(expected=True)) or
                            (self.known_streams[net_hash][name].get_uuid(expected=True) is None and
                             self.known_streams[net_hash][name].get_uuid(expected=False) is None and
                             data_uuid is not None)):

                        # setting what was the expected UUID as the local UUID from now on
                        self.known_streams[net_hash][name].set_uuid(data_uuid, expected=False)  # setting current
                        self.known_streams[net_hash][name].set_uuid(None, expected=True)  # clearing expected

                        if AgentBasics.DEBUG:
                            self.deb(f"[get_stream_sample] switched uuid")
                            self.deb(f"[get_stream_sample] let's print again, "
                                     f"self.known_streams[net_hash][name].get_tag()="
                                     f"{self.known_streams[net_hash][name].get_tag()}, "
                                     f"stream.get_uuid(expected=False)="
                                     f"{self.known_streams[net_hash][name].get_uuid(expected=False)}, "
                                     f"stream.get_uuid(expected=True)="
                                     f"{self.known_streams[net_hash][name].get_uuid(expected=True)}")

                    # buffering data, if it was requested and if this sample comes from somebody's processor
                    if (self.buffer_generated_by_others != "none" and
                            DataProps.name_or_group_from_net_hash(net_hash) == "processor"):
                        self.deb(f"[get_stream_sample] Buffering others' processor generated data...")

                        # getting the streams of the processor of the source agent
                        _processor_stream_dict = self.known_streams[net_hash]
                        _peer_id = DataProps.peer_id_from_net_hash(net_hash)

                        # setting buffered stream counter
                        clear = False
                        if _peer_id in self._last_buffered_peer_id_to_info:
                            if self.buffer_generated_by_others == "one":
                                _buffered_uuid_to_id = self._last_buffered_peer_id_to_info[_peer_id]["uuid_to_id"]
                                if data_uuid not in _buffered_uuid_to_id:
                                    _id = next(iter(_buffered_uuid_to_id.values()))
                                    _buffered_uuid_to_id.clear()
                                    _buffered_uuid_to_id[data_uuid] = _id
                                    clear = True
                        else:
                            self._last_buffered_peer_id_to_info[_peer_id] = {"uuid_to_id": {},
                                                                             "net_hash": None}
                        _buffered_uuid_to_id = self._last_buffered_peer_id_to_info[_peer_id]["uuid_to_id"]
                        if data_uuid not in _buffered_uuid_to_id:
                            _buffered_uuid_to_id[data_uuid] = sum(
                                len(v["uuid_to_id"]) for v in self._last_buffered_peer_id_to_info.values()) + 1
                        _buffered_id = _buffered_uuid_to_id[data_uuid]

                        # building net hash to retrieve the buffered stream
                        _net_hash = DataProps.build_net_hash(
                            _peer_id,
                            pubsub=False,
                            name_or_group=("buffered" + str(_buffered_id)))

                        # if the buffered stream was not created before
                        if _net_hash not in self.known_streams:
                            self.deb(f"[get_stream_sample] Adding a new buffered stream to the list of known "
                                     f"streams, hash: {_net_hash}")
                            for stream_obj in _processor_stream_dict.values():

                                # same properties of the stream of the processor of the source agent
                                props = stream_obj.get_props().clone()
                                props.set_group("buffered" + str(_buffered_id))

                                # adding the newly created stream
                                self.add_stream(BufferedDataStream(props=props, clock=self._node_clock),
                                                owned=False,
                                                net_hash=_net_hash)

                            # saving hash of the new buffered stream
                            self._last_buffered_peer_id_to_info[_peer_id]["net_hash"] = _net_hash
                        else:
                            if clear:
                                for stream_obj in self.known_streams[_net_hash].values():
                                    stream_obj.clear_buffer()

                        # saving sample
                        self.known_streams[_net_hash][name].set(data, data_tag)

                        # clearing all UUID of the locally buffered stream
                        self.known_streams[_net_hash][name].set_uuid(None, expected=False)
                        self.known_streams[_net_hash][name].set_uuid(None, expected=True)

                # if we decided to skip this sample...
                else:
                    self.out(f"Skipping a tensor named {name} (unknown/not-compatible or simply None)...")

                    if AgentBasics.DEBUG:
                        if data is None:
                            self.deb(f"In particular, data is None")
                        else:
                            self.deb(f"In particular, data is not None")
                        if name in self.known_streams[net_hash]:
                            self.deb(f"In particular, I will store in self.known_streams[{net_hash}][{name}]")
                            self.deb(f"In particular, data_tag is {str(data_tag)} and "
                                     f"self.known_streams[net_hash][name].get_tag() is "
                                     f"{str(self.known_streams[net_hash][name].get_tag())}; "
                                     f"data_uuid is {data_uuid} and "
                                     f"self.known_streams[net_hash][name].get_uuid(expected=True) is "
                                     f"{self.known_streams[net_hash][name].get_uuid(expected=True)} and "
                                     f"self.known_streams[net_hash][name].get_uuid(expected=False) is "
                                     f"{self.known_streams[net_hash][name].get_uuid(expected=False)}")
            return True

        # if this stream is not known at all...
        else:
            self.out(f"Skipping stream sample from {net_hash} (unknown/not-subscribed)...")
            return False

    def send_stream_samples(self):
        """Collect and send stream samples from all owned streams to appropriate recipients."""

        # get samples from all the owned streams
        for net_hash, streams_dict in self.owned_streams.items():

            # preparing content to send
            something_to_send = False
            content = {name: {} for name in streams_dict.keys()}
            for name, stream in streams_dict.items():
                data = stream.get(requested_by="send_stream_samples")

                if data is not None:
                    something_to_send = True
                    self.deb(f"[send_stream_samples] Preparing to send stream samples from {net_hash}, {name} "
                            f"(data_tag: {stream.get_tag()}, data_uuid: {stream.get_uuid()})")

                content[name] = {'data': data, 'data_tag': stream.get_tag(), 'data_uuid': stream.get_uuid()}

                stream.clear_uuid_if_marked_as_clearable()

            # checking if there is something valid in this group of streams
            if not something_to_send:
                continue

            # guessing recipient of direct message (if None, then PubSub)
            recipient = self._recipients[net_hash]

            # debug: force pubsub to be sent as direct message to the first agent
            # if self._recipients[net_hash] is None:
            #    for peer_id in self.all_agents.keys():
            #        recipient = peer_id
            #        break

            # if pubsub...
            if recipient is None:
                if DataStream.is_pubsub_from_net_hash(net_hash):
                    self.deb(f"[send_stream_samples] Sending stream samples of the whole {net_hash} by pubsub")

                    peer_id = DataStream.peer_id_from_net_hash(net_hash)  # guessing agent peer ID from the net hash
                    ret = self._node_conn.publish(peer_id, channel=net_hash,
                                                  content_type=Msg.STREAM_SAMPLE,
                                                  content=content)

                    self.deb(f"[send_stream_samples] sending returned: " + str(ret))

            # if direct message...
            else:
                if not DataStream.is_pubsub_from_net_hash(net_hash):
                    _recipients = recipient if isinstance(recipient, list) else [recipient]
                    for i, _recipient in enumerate(_recipients):
                        self.deb(f"[send_stream_samples] Sending samples by direct message, to {_recipient}")

                        peer_id = _recipient  # peer ID from the recipient information
                        name_or_group = DataProps.name_or_group_from_net_hash(net_hash)
                        ret = self._node_conn.send(peer_id, channel_trail=name_or_group,
                                                   content_type=Msg.STREAM_SAMPLE,
                                                   content=content)

                        self.deb(f"[send_stream_samples] sending returned: " + str(ret))
                else:
                    raise ValueError(f"Unexpected scenario: recipient set ({recipient}) and sending on a pubsub stream")

    def get_action_step(self):
        """Retrieve the current action step from the agent's private/world behavior.

        Returns:
            The current action step object from the HybridStateMachine's active action, or None if no action.
        """
        behav = self.behav if self.behav.is_enabled() else self.behav_lone_wolf
        return behav.get_action_step()

    def is_last_action_step(self):
        """Check if the agent's current action (private/world behaviour) is on its last step.

        Returns:
            True if the current action was its last step, False otherwise. Returns None if there is no active action.
        """
        behav = self.behav if self.behav.is_enabled() else self.behav_lone_wolf
        action = behav.get_action()
        if action is not None:
            return action.was_last_step_done()
        else:
            return None

    def is_multi_steps_action(self):
        behav = self.behav if self.behav.is_enabled() else self.behav_lone_wolf
        action = behav.get_action()
        return action.is_multi_steps()

    def proc_callback_inputs(self, inputs):
        self.proc_last_inputs = inputs
        return inputs

    def proc_callback_outputs(self, outputs):
        self.proc_last_outputs = outputs
        return outputs

    def save(self, where: str = "output"):
        """Save the agent's state, including its processor and other attributes, to a specified location.

        Args:
            where: The directory path where the agent's state should be saved. Defaults to "output".

        Returns:
            The string "<SAVE_OK>" upon successful saving.

        Raises:
            IOError: If there is an issue with file operations (e.g., directory creation, writing files).
            TypeError, ValueError, RuntimeError: For other potential issues during serialization or saving.
        """

        # saving the processor
        if self.proc is not None:
            torch.save(self.proc.state_dict(), os.path.join(where, f"{self._node_name}.pt"))

        try:
            # creating output folder
            if not os.path.exists(where):
                os.makedirs(where)

            # saving the whole thing (excluding the processor)
            proc = self.proc
            self.proc = None
            with open(os.path.join(where, f"{self._node_name}.pkl"), "wb") as f:
                pickle.dump(self, f)
            self.proc = proc
        except (TypeError, ValueError, RuntimeError, IOError, FileNotFoundError) as e:
            self.out("Could not save " + ("agent" if not self.is_world else "world") + f" {self._node_name}: {e}")
            raise e

        return "<SAVE_OK>"  # this means OK

    def load(self, where: str = "output"):
        """Load the agent's state from a specified location.

        Args:
            where: The directory path from which the agent's state should be loaded. Defaults to "output".

        Returns:
            The loaded AgentBasics object.

        Raises:
            AssertionError: If the specified load path does not exist.
            IOError: If there is an issue with file operations (e.g., reading files).
        """

        # checking output folder
        assert os.path.exists(where), f"Invalid load path: {where}"
        load_proc = self.proc is not None

        # loading the whole object (no processor)
        with open(os.path.join(where, f"{self._node_name}.pkl"), "rb") as f:
            loaded = pickle.load(f)

        # update self's attributes with the loaded object's attributes
        self.__dict__.update(loaded.__dict__)

        # loading the processor
        if load_proc:
            self.proc.load_state_dict(torch.load(os.path.join(where, f"{self._node_name}.pt")))

        return loaded

    def __str__(self):
        """String representation of an agent.

        Returns:
            A formatted string describing the agent's current state and relationships.
        """
        s = ("[" + ("Agent" if not self.is_world else "World") + "]"
             + f" {self._node_name} (role: {self._node_profile.get_dynamic_profile()['connections']['role']})")
        if len(self.world_masters) > 0:
            s += "\n\t- known world masters:"
            for _s in self.world_masters.keys():
                s += "\n\t\t" + str(_s)
        if len(self.world_agents) > 0:
            s += "\n\t- known agents living in the same world (non-world-masters):"
            for _s in self.world_agents.keys():
                s += "\n\t\t" + str(_s)
        if len(self.public_agents) > 0:
            s += "\n\t- known lone wolves:"
            for _s in self.public_agents.keys():
                s += "\n\t\t" + str(_s)
        if len(self.known_streams) > 0:
            s += "\n\t- known_streams:"
            for _s in self.known_streams:
                s += "\n\t\t" + str(_s)
        s += "\n\t- behaviour:"
        s += "\n\t\t" + (str(self.behav).replace("\n", "\n\t\t") if self.behav is not None else "none")
        s += "\n\t- processor:"
        s += "\n\t\t" + (str(self.proc).replace("\n", "\n\t\t") if self.proc is not None else "none")
        return s

    def __remove_all_world_related_agents(self):
        """Remove all world-related agents (masters and regular agents) from the agent's known lists."""

        to_remove = list(self.world_masters.keys())
        for peer_id in to_remove:
            self.remove_agent(peer_id)
            if peer_id in self._last_buffered_peer_id_to_info:
                del self._last_buffered_peer_id_to_info[peer_id]

        to_remove = list(self.world_agents.keys())
        for peer_id in to_remove:
            self.remove_agent(peer_id)
            if peer_id in self._last_buffered_peer_id_to_info:
                del self._last_buffered_peer_id_to_info[peer_id]

    def __remove_all_world_private_streams(self):
        """Remove all known streams that are flagged as not-public and are not owned by this agent."""

        # find what to remove
        to_remove = []
        for net_hash, stream_dict in self.known_streams.items():
            for name, stream_obj in stream_dict.items():
                if not stream_obj.get_props().is_public() and net_hash not in self.owned_streams:
                    to_remove.append((DataProps.peer_id_from_net_hash(net_hash), name))

        # remove it
        for (peer_id, name) in to_remove:
            self.remove_streams(peer_id, name)

        # clear recipients associated to these streams
        recipient_net_hashes = list(self._recipients.keys())
        for net_hash in recipient_net_hashes:
            if net_hash not in self.known_streams:
                del self._recipients[net_hash]
